# Emotion-recognition
Emotion recognition from text, audio, and video is challenging because it requires understanding spatial features . 
A comprehensive multi-modal emotion recognition system using hybrid CNN-RNN architectures. Recognizes emotions from text, audio, and video inputs with state-of-the-art accuracy.

Features
Multi-Modal Support: Text, audio, and video emotion recognition
Hybrid Architecture: CNN for spatial features, RNN for temporal context
Attention Mechanism: Shows which modality contributes most to prediction
Web Interface: Modern, responsive UI for easy interaction
RESTful API: Flexible API for integration
Real-time Processing: Fast inference on CPU/GPU
<img width="1000" height="750" alt="emotion-recognition" src="https://github.com/user-attachments/assets/b7719665-565d-4502-bc22-c3ea674ee814" />
<p align="center">System Architecture</p>

<p align="center" >
  <img src="https://github.com/user-attachments/assets/d97d269f-dca7-465b-ab9b-4e8ea4695eaa" width="500" />
</p>

